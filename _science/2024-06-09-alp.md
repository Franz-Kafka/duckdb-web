---
layout: post
title: "ALP: Adaptive Lossless Floating-Point Compression"
author: "Azim Afroozeh, Leonardo X. Kuffo, Peter A. Boncz"
thumb: "/images/science/thumbs/sigmod-2024.svg"
image: "/images/science/thumbs/sigmod-2024.png"
excerpt: ""
tags: ["Paper"]
---

[Paper (PDF)](https://ir.cwi.nl/pub/33334/33334.pdf)

Venue: SIGMOD 2024

## Abstract

IEEE 754 doubles do not exactly represent most real values, introducing rounding errors in computations and [de]serialization to text. These rounding errors inhibit the use of existing lightweight compression schemes such as Delta and Frame Of Reference (FOR), but recently new schemes were proposed: Gorilla, Chimp128, PseudoDecimals (PDE), Elf and Patas. However, their compression ratios are not better than those of general-purpose compressors such as Zstd; while [de]compression is much slower than Delta and FOR. We propose and evaluate ALP, that significantly improves these previous schemes in both speed and compression ratio. We created ALP after carefully studying the datasets used to evaluate the previous schemes. To obtain speed, ALP is designed to fit vectorized execution. This turned out to be key for also improving the compression ratio, as we found in-vector commonalities to create compression opportunities. ALP is an adaptive scheme that uses a strongly enhanced version of PseudoDecimals [31] to losslessly encode doubles as integers if they originated as decimals, and otherwise uses vectorized compression of the doublesâ€™ front bits. Its high speeds stem from our implementation in scalar code that auto-vectorizes, using building blocks provided by our FastLanes library [6], and an efficient two-stage compression algorithm that first samples row-groups and then vectors.

## Implementation

The ALP algorithm is the default compression method for floating-point numbers in DuckDB.
